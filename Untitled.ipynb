{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tweets import read_tweets\n",
    "tweets = read_tweets('data/social/twitter_cikm_2010/training_set_tweets.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "isis_tweets = pd.read_csv('data/social/how-isis-uses-twitter/tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def parse_datetime(time):\n",
    "    return str(datetime.strptime(time, \"%m/%d/%Y %H:%M\"))\n",
    "\n",
    "for tweet in tweets:\n",
    "    tweet['user'] = str(tweet['user'])\n",
    "    date = datetime.strptime(tweet['datetime'], '%Y-%m-%d %H:%M:%S')\n",
    "    tweet['datetime'] = str(date + timedelta(days=256 * 8 + 9 * 30))\n",
    "\n",
    "for idx, isis_tweet in isis_tweets.iterrows():\n",
    "    tweets.append({\n",
    "        'datetime': parse_datetime(isis_tweet['time']),\n",
    "        'text': isis_tweet['tweets'],\n",
    "        'user': isis_tweet['username'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import regex\n",
    "names = defaultdict(int)\n",
    "\n",
    "for tweet in tweets:\n",
    "    matches = regex.finditer('@(?<username>[A-Za-z0-9_]+)(?:[^\\w\\d]|$)', tweet['text'])\n",
    "    for match in matches:\n",
    "        names[match.group('username')] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(names.items(), key=lambda x: x[1], reverse=True)[250:350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "active_users = defaultdict(int)\n",
    "\n",
    "for tweet in tweets:\n",
    "    if tweet['user'].isdigit():\n",
    "        active_users[tweet['user']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(active_users.items(), key=lambda x: x[1], reverse=True)[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapping = zip(\n",
    "    sorted(active_users.items(), key=lambda x: x[1], reverse=True)[0:100],\n",
    "    sorted(names.items(), key=lambda x: x[1], reverse=True)[250:350])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tweet in tweets:\n",
    "    if tweet['user'] in mapping:\n",
    "        tweet['user'] = mapping[tweet['user']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Hoeveel namen zijn zowel twitteraars als gebruikers die ook gementioned worden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(reduce(lambda acc, values: acc | values, isis_network.values(), set()) & set(isis_network.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Netwerkgraaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "nodes = set(isis_network.keys())\n",
    "\n",
    "for names in isis_network.values():\n",
    "    nodes |= set(names.keys())\n",
    "\n",
    "nodes = list(nodes)\n",
    "    \n",
    "edges = list()\n",
    "\n",
    "for user, names in isis_network.items():\n",
    "    for name, count in names.items():\n",
    "        edges.append((nodes.index(user), nodes.index(name), count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def direction(edge):\n",
    "    for an_edge in edges:\n",
    "        if an_edge[0] == edge[1] and an_edge[1] == edge[0]:\n",
    "            return \"both\"\n",
    "    return \"out\"\n",
    "\n",
    "output = dict()\n",
    "output['nodes'] = [dict(id=idx, label=name) for idx, name in enumerate(nodes)]\n",
    "output['edges'] = [dict(source=edge[0], target=edge[1], count=edge[2], direction=direction(edge)) for edge in edges]\n",
    "\n",
    "output['edges'] = filter(lambda x: x['count'] > 1, output['edges'])\n",
    "mentioned_nodes = reduce(lambda acc, x: acc | set(x), ((edge['source'], edge['target']) for edge in output['edges']), set())\n",
    "output['nodes'] = filter(lambda node: node['id'] in mentioned_nodes, output['nodes'])\n",
    "\n",
    "\n",
    "with open('graph.json', 'w') as fh:\n",
    "    json.dump(output, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Netwerkgraaf over tijd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network 2\n",
      "Network 5\n",
      "Network 7\n",
      "Network 10\n",
      "Network 13\n",
      "Network 15\n",
      "Network 18\n",
      "Network 21\n",
      "Network 23\n",
      "Network 26\n",
      "Network 29\n",
      "Network 31\n",
      "Network 34\n",
      "Network 37\n",
      "Network 39\n",
      "Network 42\n",
      "Network 45\n",
      "Network 47\n",
      "Network 50\n",
      "Network 53\n",
      "Network 55\n",
      "Network 58\n",
      "Network 61\n",
      "Network 63\n",
      "Network 66\n",
      "Network 69\n",
      "Network 71\n",
      "Network 74\n",
      "Network 77\n",
      "Network 79\n",
      "Network 82\n",
      "Network 85\n",
      "Network 87\n",
      "Network 90\n",
      "Network 93\n",
      "Network 95\n",
      "Network 98\n",
      "Deleting 82382 users. Bye bye!\n",
      "Nodeset 46\n",
      "Nodeset 92\n",
      "Edges 46\n",
      "Edges 92\n"
     ]
    }
   ],
   "source": [
    "import regex\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "network = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "n = 0\n",
    "\n",
    "for tweet in tweets:\n",
    "    n += 1\n",
    "    if n % 100000 == 0:\n",
    "        print(\"Network %d\" % (100 * n / len(tweets)))\n",
    "    matches = regex.finditer('@(?<username>[A-Za-z0-9_]+)(?:[^\\w\\d]|$)', tweet['text'])\n",
    "    for match in matches:\n",
    "        network[tweet['user']][match.group('username')].append(tweet['datetime'])\n",
    "\n",
    "to_delete = set()\n",
    "for name, mentions in network.items():\n",
    "    if sum(len(times) for times in mentions.values()) < 100:\n",
    "        to_delete.add(name)\n",
    "\n",
    "print(\"Deleting {} users. Bye bye!\".format(len(to_delete)))\n",
    "\n",
    "for name in to_delete:\n",
    "    del network[name]\n",
    "        \n",
    "nodeset = set(network.keys())\n",
    "\n",
    "n = 0\n",
    "for values in network.values():\n",
    "    n += 1\n",
    "    if n % 1000 == 0:\n",
    "        print(\"Nodeset %d\" % (100 * n / len(network)))\n",
    "    nodeset.update(values)\n",
    "\n",
    "nodes = list(nodeset)\n",
    "    \n",
    "edges = list()\n",
    "\n",
    "nodes_index = dict([(name, idx) for idx, name in enumerate(nodes)])\n",
    "\n",
    "n = 0\n",
    "for name, mentions in network.items():\n",
    "    n += 1\n",
    "    if n % 1000 == 0:\n",
    "        print(\"Edges %d\" % (100 * n / len(network)))\n",
    "    for mentioned_name, times in mentions.items():\n",
    "        edges.append({\n",
    "            'source': nodes_index[name],\n",
    "            'target': nodes_index[mentioned_name],\n",
    "            'times': times\n",
    "        })\n",
    "\n",
    "output = {\n",
    "    'nodes': [{'id': idx, 'label': name} for idx, name in enumerate(nodes)],\n",
    "    'edges': edges\n",
    "}\n",
    "\n",
    "with open('graph-times-complete-min-100-fake.json', 'w') as fh:\n",
    "    json.dump(output, fh, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('isis_tweets.csv', 'w') as fh:\n",
    "    writer = csv.writer(fh)\n",
    "    for tweet in isis_tweets.T.to_dict().values():\n",
    "        tweet['description'] = re.sub('[\\r\\n\\s,]+', ' ', tweet['description'] if isinstance(tweet['description'], str) else '')\n",
    "        tweet['tweets'] = re.sub('[\\r\\n\\s,]+', ' ', tweet['tweets'])\n",
    "        writer.writerow(tweet.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('all_tweets.csv', 'w') as fh:\n",
    "    writer = csv.writer(fh)\n",
    "    for tweet in tweets:\n",
    "        writer.writerow([\n",
    "            tweet['user'],\n",
    "            tweet['tweet_id'],\n",
    "            tweet['datetime'],\n",
    "            re.sub('[\\r\\n\\s,]+', ' ', tweet['text'])\n",
    "        ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
